\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{spbasic}
\citation{AITS_THEORY,AITS_PRACTICE}
\citation{BTAI_BF}
\citation{FRISTON2016862,AI_TUTO,AI_VMP}
\citation{PAI}
\citation{FRISTON2016862}
\citation{bayes_surprise}
\citation{curiosity}
\citation{dopamine}
\citation{DeepAIwithMCMC}
\citation{pezzato2020active,sancaktar2020endtoend}
\citation{catal2020learning}
\citation{CULLEN2018809}
\citation{cart_pole}
\citation{MCTS}
\citation{AITS_THEORY,AITS_PRACTICE}
\citation{VMP_TUTO,AI_VMP}
\citation{BAYESIAN_FILTERING}
\citation{BTAI_BF}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{BP_and_DC,believe,belief_propagation}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theory of $BTAI_{3MF}$}{2}{section.2}\protected@file@percent }
\newlabel{sec:btai_3mf}{{2}{2}{}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Temporal slice}{3}{subsection.2.1}\protected@file@percent }
\newlabel{ssec:temporal_slice}{{2.1}{3}{Temporal slice}{subsection.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  This figure illustrates two temporal slices $TS_t$ and $TS_I$, which are depicted by rectangles with thick border. Within each temporal slice, plate notation is used to generate $\# S$ latent states and $\# O$ observations. The dashed lines that connect two random variables from two different plates are new to this paper, and represent an arbitrary connectivity between the two sets of random variables generated by the plates. For example, the dashed line from $S_t^s$ to $O_t^o$, means that for each observation $O_t^o$, the parents of $O_t^o$ denoted $\rho _t^o$ is a subset of $\{S_t^s \mid s = 1, \mathellipsis  , \# S\}$, i.e., the generative model contains the factor $P(O_t^o | \rho _t^o)$ where $\rho _t^o \subseteq \{S_t^s \mid s = 1, \mathellipsis  , \# S\}$. \relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:temporal_slice}{{1}{3}{This figure illustrates two temporal slices $TS_t$ and $TS_I$, which are depicted by rectangles with thick border. Within each temporal slice, plate notation is used to generate $\nb {S}$ latent states and $\nb {O}$ observations. The dashed lines that connect two random variables from two different plates are new to this paper, and represent an arbitrary connectivity between the two sets of random variables generated by the plates. For example, the dashed line from $S_t^s$ to $O_t^o$, means that for each observation $O_t^o$, the parents of $O_t^o$ denoted $\rho _t^o$ is a subset of $\{S_t^s \mid s = 1, \hdots , \nb {S}\}$, i.e., the generative model contains the factor $P(O_t^o | \rho _t^o)$ where $\rho _t^o \subseteq \{S_t^s \mid s = 1, \hdots , \nb {S}\}$. \relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  This figure illustrates the two temporal slices $TS_t$ and $TS_I$ from Figure \ref  {fig:temporal_slice} in a more compact fashion. Since $O_t^o$ is an observed variable for all $o \in \{1, \mathellipsis  , \# O\}$, the square representing $TS_t$ has a gray background. In contrast, the square representing $TS_I$ has a white background because $O_I^o$ is a latent variable for all $o \in \{1, \mathellipsis  , \# O\}$. \relax }}{3}{figure.caption.2}\protected@file@percent }
\newlabel{fig:temporal_slice_compact}{{2}{3}{This figure illustrates the two temporal slices $TS_t$ and $TS_I$ from Figure \ref {fig:temporal_slice} in a more compact fashion. Since $O_t^o$ is an observed variable for all $o \in \{1, \hdots , \nb {O}\}$, the square representing $TS_t$ has a gray background. In contrast, the square representing $TS_I$ has a white background because $O_I^o$ is a latent variable for all $o \in \{1, \hdots , \nb {O}\}$. \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Generative model}{3}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  This figure illustrates the full generative model of $BTAI_{3MF}$. The temporal slices depited in light gray correspond to temporal slices that have not yet been explored by the planning algorithm, c.f., Section \ref  {ssec:planning}. The numbers between parentheses correspond to the sequence of actions performed to reach the temporal slice. \relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:generative_model}{{3}{4}{This figure illustrates the full generative model of $BTAI_{3MF}$. The temporal slices depited in light gray correspond to temporal slices that have not yet been explored by the planning algorithm, c.f., Section \ref {ssec:planning}. The numbers between parentheses correspond to the sequence of actions performed to reach the temporal slice. \relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Belief updates: the inference and prediction (IP) algorithm}{5}{subsection.2.3}\protected@file@percent }
\newlabel{ssec:IP_algorithm}{{2.3}{5}{Belief updates: the inference and prediction (IP) algorithm}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Inference step}{5}{subsubsection.2.3.1}\protected@file@percent }
\newlabel{ssec:i_step}{{2.3.1}{5}{Inference step}{subsubsection.2.3.1}{}}
\citation{belief_propagation}
\citation{BAYESIAN_FILTERING}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Prediction step}{6}{subsubsection.2.3.2}\protected@file@percent }
\newlabel{ssec:p_step}{{2.3.2}{6}{Prediction step}{subsubsection.2.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Expected Free Energy}{7}{subsection.2.4}\protected@file@percent }
\newlabel{ssec:efe}{{2.4}{7}{Expected Free Energy}{subsection.2.4}{}}
\newlabel{eq:efe}{{1}{7}{Expected Free Energy}{equation.2.1}{}}
\citation{MCTS}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Planning: the MCTS algorithm}{8}{subsection.2.5}\protected@file@percent }
\newlabel{ssec:planning}{{2.5}{8}{Planning: the MCTS algorithm}{subsection.2.5}{}}
\newlabel{eq:UCT}{{2}{8}{Planning: the MCTS algorithm}{equation.2.2}{}}
\newlabel{eq:backprop}{{3}{8}{Planning: the MCTS algorithm}{equation.2.3}{}}
\newlabel{eq:backprop_n}{{4}{8}{Planning: the MCTS algorithm}{equation.2.4}{}}
\citation{MCTS}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Action selection}{9}{subsection.2.6}\protected@file@percent }
\newlabel{ssec:action_selection}{{2.6}{9}{Action selection}{subsection.2.6}{}}
\newlabel{eq:action_selection}{{5}{9}{Action selection}{equation.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Closing the action-perception cycle}{9}{subsection.2.7}\protected@file@percent }
\citation{dsprites17}
\citation{VAE}
\newlabel{algo:BTAI_3MF_cycles}{{1}{10}{Closing the action-perception cycle}{algocfline.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces $BTAI_{3MF}$: action-perception cycles (with relevant equations indicated in round brackets).\relax }}{10}{algocf.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{10}{section.3}\protected@file@percent }
\newlabel{sec:results}{{3}{10}{Closing the action-perception cycle}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}dSprites Environment}{10}{subsection.3.1}\protected@file@percent }
\newlabel{ssec:dsprites}{{3.1}{10}{dSprites Environment}{subsection.3.1}{}}
\citation{STATES_AGGREG}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces This figure illustrates the dSprites environment, in which the agent must move all squares towards the bottom-left corner of the image and all ellipses and hearts towards the bottom-right corner of the image. The red arrows show the behaviour expected from the agent.\relax }}{11}{figure.caption.4}\protected@file@percent }
\newlabel{fig:dSprites_env}{{4}{11}{This figure illustrates the dSprites environment, in which the agent must move all squares towards the bottom-left corner of the image and all ellipses and hearts towards the bottom-right corner of the image. The red arrows show the behaviour expected from the agent.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  This figure illustrates the observations made by the agent when using a coarse-grained representation with a granularity of eight on the input image. On the left, one can see an image from the dSprites dataset and a grid containing red squares of $8\times 8$ pixels. Any positions in those $8\times 8$ squares are indistinguishable from the perspective of the agent. Also, the bottom most row is an absorbing row used to specify the prior preferences of the agent, i.e. the green square is the goal state and the orange squares correspond to undesirable states. Finally, the three tables on the right contain the indices observed by the $BTAI_{VMP}$ and $BTAI_{BF}$ agents for each type of shape at each possible position.\relax }}{11}{figure.caption.5}\protected@file@percent }
\newlabel{fig:down_sampling}{{5}{11}{This figure illustrates the observations made by the agent when using a coarse-grained representation with a granularity of eight on the input image. On the left, one can see an image from the dSprites dataset and a grid containing red squares of $8\times 8$ pixels. Any positions in those $8\times 8$ squares are indistinguishable from the perspective of the agent. Also, the bottom most row is an absorbing row used to specify the prior preferences of the agent, i.e. the green square is the goal state and the orange squares correspond to undesirable states. Finally, the three tables on the right contain the indices observed by the $BTAI_{VMP}$ and $BTAI_{BF}$ agents for each type of shape at each possible position.\relax }{figure.caption.5}{}}
\citation{AITS_THEORY,AITS_PRACTICE}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}$BTAI_{VMP}$ modeling approach and results}{12}{subsection.3.2}\protected@file@percent }
\newlabel{ssec:btai_vmp}{{3.2}{12}{$BTAI_{VMP}$ modeling approach and results}{subsection.3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The value of each hyper-parameter used by $BTAI_{VMP}$ in this section. \url  {NB_SIMULATIONS} is the number of simulations run during the experiment. \url  {NB_ACTION_PERCEPTION_CYCLES} is the maximum number of actions executed in each simulation, after which the simulation is terminated. \url  {NB_PLANNING_STEPS} is the number of planning iterations performed by the agent. \url  {EXPLORATION_CONSTANT} is the exploration constant of the UCT criterion. \url  {PRECISION_PRIOR_PREFERENCES} is the precision of the prior preferences. \url  {PRECISION_ACTION_SELECTION} is the precision of the distribution used for action selection. \url  {EVALUATION_TYPE} is the type of cost used to evaluate the node during the tree search. Those hyper-parameters can be used to re-run the experiments using the code of the following GitHub repository: \url  {https://github.com/ChampiB/Experiments_AI_TS}.\relax }}{12}{table.caption.6}\protected@file@percent }
\newlabel{tab:values_hp_BTAI_dSprites}{{1}{12}{The value of each hyper-parameter used by $BTAI_{VMP}$ in this section. \url {NB_SIMULATIONS} is the number of simulations run during the experiment. \url {NB_ACTION_PERCEPTION_CYCLES} is the maximum number of actions executed in each simulation, after which the simulation is terminated. \url {NB_PLANNING_STEPS} is the number of planning iterations performed by the agent. \url {EXPLORATION_CONSTANT} is the exploration constant of the UCT criterion. \url {PRECISION_PRIOR_PREFERENCES} is the precision of the prior preferences. \url {PRECISION_ACTION_SELECTION} is the precision of the distribution used for action selection. \url {EVALUATION_TYPE} is the type of cost used to evaluate the node during the tree search. Those hyper-parameters can be used to re-run the experiments using the code of the following GitHub repository: \url {https://github.com/ChampiB/Experiments_AI_TS}.\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The percentage of the dSprites environment solved by the $BTAI_{VMP}$ agent when using a granularity of eight, c.f. Figure \ref  {fig:down_sampling}. The last column reports the average execution time required for one simulation and the associated standard deviation.\relax }}{12}{table.caption.7}\protected@file@percent }
\newlabel{tab:dSprites_res_8}{{2}{12}{The percentage of the dSprites environment solved by the $BTAI_{VMP}$ agent when using a granularity of eight, c.f. Figure \ref {fig:down_sampling}. The last column reports the average execution time required for one simulation and the associated standard deviation.\relax }{table.caption.7}{}}
\citation{BTAI_BF}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The percentage of the dSprites environment solved by the $BTAI_{VMP}$ agent when using a granularity of four. In this setting, there are $9 \times 8 \times 3 = 216$ states. The last column reports the average execution time required for one simulation and the associated standard deviation.\relax }}{13}{table.caption.8}\protected@file@percent }
\newlabel{tab:dSprites_res_4}{{3}{13}{The percentage of the dSprites environment solved by the $BTAI_{VMP}$ agent when using a granularity of four. In this setting, there are $9 \times 8 \times 3 = 216$ states. The last column reports the average execution time required for one simulation and the associated standard deviation.\relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}$BTAI_{BF}$ modeling approach and results}{13}{subsection.3.3}\protected@file@percent }
\newlabel{ssec:btai_bf}{{3.3}{13}{$BTAI_{BF}$ modeling approach and results}{subsection.3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces The value of each hyper-parameter used by $BTAI_{BF}$ in this section. \url  {NB_SIMULATIONS} is the number of simulations run during the experiment. \url  {NB_ACTION_PERCEPTION_CYCLES} is the maximum number of actions executed in each simulation, after which the simulation is terminated. \url  {NB_PLANNING_STEPS} is the number of planning iterations performed by the agent. \url  {EXPLORATION_CONSTANT} is the exploration constant of the UCT criterion. \url  {PRECISION_PRIOR_PREFERENCES} is the precision of the prior preferences. \url  {PRECISION_ACTION_SELECTION} is the precision of the distribution used for action selection. \url  {EVALUATION_TYPE} is the type of cost used to evaluate the node during the tree search. Those hyper-parameters can be used to re-run the experiments using the code of the following GitHub repository: \url  {https://github.com/ChampiB/Branching_Time_Active_Inference}.\relax }}{13}{table.caption.9}\protected@file@percent }
\newlabel{tab:values_hp_BTAI_BF_dSprites}{{4}{13}{The value of each hyper-parameter used by $BTAI_{BF}$ in this section. \url {NB_SIMULATIONS} is the number of simulations run during the experiment. \url {NB_ACTION_PERCEPTION_CYCLES} is the maximum number of actions executed in each simulation, after which the simulation is terminated. \url {NB_PLANNING_STEPS} is the number of planning iterations performed by the agent. \url {EXPLORATION_CONSTANT} is the exploration constant of the UCT criterion. \url {PRECISION_PRIOR_PREFERENCES} is the precision of the prior preferences. \url {PRECISION_ACTION_SELECTION} is the precision of the distribution used for action selection. \url {EVALUATION_TYPE} is the type of cost used to evaluate the node during the tree search. Those hyper-parameters can be used to re-run the experiments using the code of the following GitHub repository: \url {https://github.com/ChampiB/Branching_Time_Active_Inference}.\relax }{table.caption.9}{}}
\citation{10.1162/neco_a_01357}
\citation{DeepAIwithMCMC}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces The percentage of the dSprites environment solved by the $BTAI_{BF}$ agent when using a granularity of eight, four and two. Note, when a granularity of two is used, there are $17 \times 16 \times 3 = 816$ possible states. The last column reports the average execution time required for one simulation and the associated standard deviation. Note, the change in time granularity to milliseconds.\relax }}{14}{table.caption.10}\protected@file@percent }
\newlabel{tab:btai_bf_dSprites_res}{{5}{14}{The percentage of the dSprites environment solved by the $BTAI_{BF}$ agent when using a granularity of eight, four and two. Note, when a granularity of two is used, there are $17 \times 16 \times 3 = 816$ possible states. The last column reports the average execution time required for one simulation and the associated standard deviation. Note, the change in time granularity to milliseconds.\relax }{table.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}$BTAI_{3MF}$ modeling approach and results}{14}{subsection.3.4}\protected@file@percent }
\newlabel{ssec:btai_3mf}{{3.4}{14}{$BTAI_{3MF}$ modeling approach and results}{subsection.3.4}{}}
\citation{AITS_THEORY,AITS_PRACTICE}
\citation{BTAI_BF}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces The value of each hyper-parameter used by $BTAI_{3MF}$ in this section. \url  {NB_SIMULATIONS} is the number of simulations run during the experiment. \url  {NB_ACTION_PERCEPTION_CYCLES} is the maximum number of actions executed in each simulation, after which the simulation is terminated. \url  {NB_PLANNING_STEPS} is the number of planning iterations performed by the agent. \url  {EXPLORATION_CONSTANT} is the exploration constant of the UCT criterion. \url  {PRECISION_PRIOR_PREFERENCES} is the precision of the prior preferences. \url  {EVALUATION_TYPE} is the type of cost used to evaluate the node during the tree search. Those hyper-parameters can be used to re-run the experiments using the code of the following GitHub repository: \url  {https://github.com/ChampiB/BTAI_3MF}.\relax }}{15}{table.caption.11}\protected@file@percent }
\newlabel{tab:values_hp_BTAI_3MF_dSprites}{{6}{15}{The value of each hyper-parameter used by $BTAI_{3MF}$ in this section. \url {NB_SIMULATIONS} is the number of simulations run during the experiment. \url {NB_ACTION_PERCEPTION_CYCLES} is the maximum number of actions executed in each simulation, after which the simulation is terminated. \url {NB_PLANNING_STEPS} is the number of planning iterations performed by the agent. \url {EXPLORATION_CONSTANT} is the exploration constant of the UCT criterion. \url {PRECISION_PRIOR_PREFERENCES} is the precision of the prior preferences. \url {EVALUATION_TYPE} is the type of cost used to evaluate the node during the tree search. Those hyper-parameters can be used to re-run the experiments using the code of the following GitHub repository: \url {https://github.com/ChampiB/BTAI_3MF}.\relax }{table.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces This table presents the percentage of the dSprites environment solved by the $BTAI_{3MF}$ agent when using a granularity of eight, four, two and one. Note, when a granularity of one is used, there are $33 \times 32 \times 3 \times 40 \times 6 = 760,320$ possible state configurations. The last column reports the average execution time required of one simulation and the associated standard deviation.\relax }}{15}{table.caption.12}\protected@file@percent }
\newlabel{tab:btai_3mf_dSprites_res}{{7}{15}{This table presents the percentage of the dSprites environment solved by the $BTAI_{3MF}$ agent when using a granularity of eight, four, two and one. Note, when a granularity of one is used, there are $33 \times 32 \times 3 \times 40 \times 6 = 760,320$ possible state configurations. The last column reports the average execution time required of one simulation and the associated standard deviation.\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{15}{section.4}\protected@file@percent }
\newlabel{sec:conclusion}{{4}{15}{$BTAI_{3MF}$ modeling approach and results}{section.4}{}}
\citation{AITS_THEORY,AITS_PRACTICE}
\citation{o2001conjunctive}
\citation{bowman2007simultaneous}
\citation{730558}
\citation{uhlhaas2009neural}
\citation{PMID:11766936}
\bibdata{references}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces This figure illustrates the visualisation frame of the GUI used to analyse a $BTAI_{3MF}$ agent. The image corresponding to the current state of the environment is displayed in the upper-left corner. Under the image are four buttons allowing the user to: reset the environment and agent, perform the next planning iteration, perform all the remaining planning iterations, and perform the current best action in the environment. Finally, on the right hand side of the image is a depiction of the MCTS planning, where $TS(t)$ represents the current temporal slice. At the moment, the current temporal slice has no children, and therefore its children are displayed in orange with the text ``None". Additionally, the current slice has no parent because it is the tree's root. Therefore, the arrow above the $TS(t)$ node is also orange.\relax }}{20}{figure.caption.15}\protected@file@percent }
\newlabel{fig:gui_vf}{{6}{20}{This figure illustrates the visualisation frame of the GUI used to analyse a $BTAI_{3MF}$ agent. The image corresponding to the current state of the environment is displayed in the upper-left corner. Under the image are four buttons allowing the user to: reset the environment and agent, perform the next planning iteration, perform all the remaining planning iterations, and perform the current best action in the environment. Finally, on the right hand side of the image is a depiction of the MCTS planning, where $TS(t)$ represents the current temporal slice. At the moment, the current temporal slice has no children, and therefore its children are displayed in orange with the text ``None". Additionally, the current slice has no parent because it is the tree's root. Therefore, the arrow above the $TS(t)$ node is also orange.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces This figure illustrates the visualisation frame of the GUI used to analyse a $BTAI_{3MF}$ agent after performing one planning iteration. The children of the root node are now available. One of them is displayed in green, it corresponds to the best action found so far by the MCTS algorithm. The root node has a red square surronding it, which means that it was selected for expansion by the MCTS algorithm.\relax }}{20}{figure.caption.16}\protected@file@percent }
\newlabel{fig:gui_vf_next_planning_step}{{7}{20}{This figure illustrates the visualisation frame of the GUI used to analyse a $BTAI_{3MF}$ agent after performing one planning iteration. The children of the root node are now available. One of them is displayed in green, it corresponds to the best action found so far by the MCTS algorithm. The root node has a red square surronding it, which means that it was selected for expansion by the MCTS algorithm.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces This figure illustrates the frame displaying the information of the current temporal slice of the $BTAI_{3MF}$ agent. Six widgets are displayed. The first displays the structure of the likelihood model using the factor graph formalism. On this graph, we see that the model is composed of five obervations and five hidden states. Each observation depends on only one hidden state. The second widget displays the structure of the transition mapping. We see that only two hidden states depend on the action taken by the agent, i.e., the hidden states corresponding to the X and Y position of the shape. The third widget shows the structure of the prior preferences. Here, there is only one factor over three random variables, i.e., the shape and its (X, Y) position. Note, when moving your mouse over a variable in the likelihood, transition or prior preference widget the complete name of the variable is displayed, e.g., when moving over ``S1" the label ``S\_shape" is displayed. The fourth widget illustrates the posterior over the latent variable corresponding to the x position of the shape. The random variable whose posterior is displayed can be changed either by using the combo box in the bottom-right corner of the widget or by clicking on a latent variable in the likelihood model widget. The fifth widget displays information related to the Monte-Carlo tree search. Finally, the last widget illustrates the message sent from the observation variable corresponding to the X position of the shape to its likelihood factor.\relax }}{21}{figure.caption.17}\protected@file@percent }
\newlabel{fig:gui_tsf_for_current_ts}{{8}{21}{This figure illustrates the frame displaying the information of the current temporal slice of the $BTAI_{3MF}$ agent. Six widgets are displayed. The first displays the structure of the likelihood model using the factor graph formalism. On this graph, we see that the model is composed of five obervations and five hidden states. Each observation depends on only one hidden state. The second widget displays the structure of the transition mapping. We see that only two hidden states depend on the action taken by the agent, i.e., the hidden states corresponding to the X and Y position of the shape. The third widget shows the structure of the prior preferences. Here, there is only one factor over three random variables, i.e., the shape and its (X, Y) position. Note, when moving your mouse over a variable in the likelihood, transition or prior preference widget the complete name of the variable is displayed, e.g., when moving over ``S1" the label ``S\_shape" is displayed. The fourth widget illustrates the posterior over the latent variable corresponding to the x position of the shape. The random variable whose posterior is displayed can be changed either by using the combo box in the bottom-right corner of the widget or by clicking on a latent variable in the likelihood model widget. The fifth widget displays information related to the Monte-Carlo tree search. Finally, the last widget illustrates the message sent from the observation variable corresponding to the X position of the shape to its likelihood factor.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces This figure illustrates what happens when clicking on the child ``TS(1)" in Figure \ref  {fig:gui_vf_next_planning_step}. Put simply, ``TS(1)" becomes the new root and we see that its children have not been expanded yet. Additionally, the arrow above the ``TS(1)" node is gray meaning that this node has a parent, i.e., ``TS(t)". Clicking on this arrow leads us back to Figure \ref  {fig:gui_vf_next_planning_step}.\relax }}{21}{figure.caption.18}\protected@file@percent }
\newlabel{fig:navigating_to_child}{{9}{21}{This figure illustrates what happens when clicking on the child ``TS(1)" in Figure \ref {fig:gui_vf_next_planning_step}. Put simply, ``TS(1)" becomes the new root and we see that its children have not been expanded yet. Additionally, the arrow above the ``TS(1)" node is gray meaning that this node has a parent, i.e., ``TS(t)". Clicking on this arrow leads us back to Figure \ref {fig:gui_vf_next_planning_step}.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces This figure illustrates what happens when clicking on ``TS(1)" in Figure \ref  {fig:navigating_to_child}. Most of the widgets have already been explained with the exception of the one in the bottom right-corner, which displays how the expected free energy decomposes into risk (blue box) and ambiguity (red box). When clicking on the blue or red box, the decomposition of the risk or ambiguity term is displayed as shown in Figure \ref  {fig:ambiguity_decomposition}.\relax }}{22}{figure.caption.19}\protected@file@percent }
\newlabel{fig:ts_frame_in_the_future}{{10}{22}{This figure illustrates what happens when clicking on ``TS(1)" in Figure \ref {fig:navigating_to_child}. Most of the widgets have already been explained with the exception of the one in the bottom right-corner, which displays how the expected free energy decomposes into risk (blue box) and ambiguity (red box). When clicking on the blue or red box, the decomposition of the risk or ambiguity term is displayed as shown in Figure \ref {fig:ambiguity_decomposition}.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces This figure illustrates how the ambiguity term decomposes into the ambiguity of the likelihood of each observed variable, i.e., the ambiguity of ``O\_shape" in blue, ``O\_scale" in red, ``O\_orientation" in orange, ``O\_pos\_x" in green, and ``O\_pos\_y" in gray.\relax }}{22}{figure.caption.20}\protected@file@percent }
\newlabel{fig:ambiguity_decomposition}{{11}{22}{This figure illustrates how the ambiguity term decomposes into the ambiguity of the likelihood of each observed variable, i.e., the ambiguity of ``O\_shape" in blue, ``O\_scale" in red, ``O\_orientation" in orange, ``O\_pos\_x" in green, and ``O\_pos\_y" in gray.\relax }{figure.caption.20}{}}
\gdef\minted@oldcachelist{,
  default-pyg-prefix.pygstyle,
  default.pygstyle,
  2A7A3425F9F64E721F28C515A8308EAB447E79978044C0C13383FCBD769CB5FF.pygtex,
  D4295211F8BBC7A8C21E11DB86D3FC35447E79978044C0C13383FCBD769CB5FF.pygtex,
  EBA2C1147AB0F21473AB0B8126CA746C447E79978044C0C13383FCBD769CB5FF.pygtex,
  B9EA44999FFE847A488E86ABD3847B24447E79978044C0C13383FCBD769CB5FF.pygtex,
  FE17C580106E23CBB988C0B2E3E2AE58447E79978044C0C13383FCBD769CB5FF.pygtex,
  DBCB0FF0888A32D45AFA09D4BEA12D7E447E79978044C0C13383FCBD769CB5FF.pygtex,
  BD42C368562E6EECABCAAF13C249A003447E79978044C0C13383FCBD769CB5FF.pygtex,
  6DA1858AD682DC6C2D8A28F6F66178A3447E79978044C0C13383FCBD769CB5FF.pygtex,
  66F33982CF6EA8C729EEA3416BCFF529447E79978044C0C13383FCBD769CB5FF.pygtex,
  DDBC157762A2B5AB87BB318EE98A6E7A447E79978044C0C13383FCBD769CB5FF.pygtex,
  F9F1FDF92F558D828DBC86673646B89C447E79978044C0C13383FCBD769CB5FF.pygtex,
  847B25A2DA626CC787D4372C1B0F5D53447E79978044C0C13383FCBD769CB5FF.pygtex}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces  This figure illustrates a Bayesian network in which the following independences assumptions \textbf  {hold}: $A \perp \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \perp B\tmspace  +\thinmuskip {.1667em}|\tmspace  +\thinmuskip {.1667em} \emptyset $; $A, D \perp \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \perp C\tmspace  +\thinmuskip {.1667em}|\tmspace  +\thinmuskip {.1667em}B$; and $A \perp \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \perp E\tmspace  +\thinmuskip {.1667em}|\tmspace  +\thinmuskip {.1667em}D, B, C$. In contrast, the following independences assumptions \textbf  {does not hold}: $A \perp \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \perp B\tmspace  +\thinmuskip {.1667em}|\tmspace  +\thinmuskip {.1667em} D$; $A \perp \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \perp E\tmspace  +\thinmuskip {.1667em}|\tmspace  +\thinmuskip {.1667em}B, C$; and $A \perp \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \tmspace  -\thinmuskip {.1667em} \perp B\tmspace  +\thinmuskip {.1667em}|\tmspace  +\thinmuskip {.1667em}E$ . \relax }}{24}{figure.caption.25}\protected@file@percent }
\newlabel{fig:d_sep_BN}{{12}{24}{This figure illustrates a Bayesian network in which the following independences assumptions \textbf {hold}: $A \indep B\,|\, \emptyset $; $A, D \indep C\,|\,B$; and $A \indep E\,|\,D, B, C$. In contrast, the following independences assumptions \textbf {does not hold}: $A \indep B\,|\, D$; $A \indep E\,|\,B, C$; and $A \indep B\,|\,E$ . \relax }{figure.caption.25}{}}
